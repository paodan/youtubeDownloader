#' Downloading by an URL seed
#' @description Download YouTube videos/audios by providing an URL seed,
#' which is any URL in a video list.
#' @param fileList the file name of video/audio list table. This table
#' is a csv file generated by \code{\link{videoListDownload}} function.
#' The columns of this table are 'rowNames', 'data.index',
#' 'data.video.title', 'fileName', and 'URL', in which 'URL' is most
#' important information.
#' @param path the path to save video/audio files.
#' @param saveFileList logic, whether save the file table.
#' @param sleepTime numeric, the time to pause to prevent YouTube blocking.
#' The default is 10 second
#' @param maxDownload integer, the maximal downloading.
#' @param priority the file format to download. The option can be
#' any one (or combination) of "mp4", "best", "audio only", "mp3",
#' "webm", the default
#' is c("mp4", "best", "audio only"), which means the downloader will
#' look for mp4 file first, if this file does not exist, then the
#' downloader will look for the best file marked by YouTube, then
#' look for only audio file.
#' @param bothVideoAudio logic, whether download both audio and video,
#' it should be FALSE if only downloading audio or video. The default
#' is \code{TRUE}.
#' @return a data.frame of video/audio list and write a csv table to `path`.
#' The columns of this table are 'rowNumber', 'Orders',
#' 'VideoTitles', 'fileName', and 'URL', in which 'URL' is most
#' important information.
#' @import curl
#' @importFrom limma strsplit2
#' @import urltools
#' @import stringr
#' @export
#' @examples {
#' \dontrun{
#' url0 = "https://www.youtube.com/watch?v=DejHQYAGb7Q&list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6"
#' # the folder to save downloaded files
#' folder = "/data/surfDrive/TutorialVideos/"
#'
#' # #### video file table
#' fileTable = videoListTable(urlSeed = url0, path = folder,
#'                            saveFileList = TRUE,
#'                            sleepTime = 5, maxDownload = 200,
#'                            bothVideoAudio = TRUE)
#' head(fileTable)
#'
#' # #### audio file table
#' fileTable = videoListTable(urlSeed = url0, path = folder,
#'                            saveFileList = TRUE,
#'                            sleepTime = 5, maxDownload = 200,
#'                            priority = c("audio only"),
#'                            bothVideoAudio = FALSE)
#' head(fileTable)
#' }
#' }
videoListTable = function(urlSeed,
                          path = "./",
                          saveFileList = TRUE,
                          sleepTime = 10,
                          maxDownload = 1000,
                          priority = c("audio only", "best", "mp4"),
                          bothVideoAudio = TRUE) {
  # copyright: Weiyang Tao 2017-11-02
  urlpage = readLines(urlSeed, warn = FALSE)
  ##### File names with orders
  # the line containing titles
  titleLine = grep("data-video-title=",
                   urlpage,
                   perl = FALSE,
                   value = TRUE)
  titleLine = gsub("&#39;", replacement = "\'", titleLine) # replace '
  titleLine = gsub("&quot;", replacement = "", titleLine) # replace "
  titleLine = gsub("\" ", replacement = "\"&", titleLine) # replace "
  titleLine = gsub("&amp;", replacement = "and", titleLine) # replace &
  # add ?a="a"& for param_get function to recognize.
  # ?a="a"& must be this format: ?text="text"&
  titleLine = paste0('?a="a"&', titleLine)

  tiOr = param_get(
    titleLine,
    parameter_names = c(
      "data-video-title",
      "data-index",
      "data-innertube-clicktracking",
      "data-video-username",
      "data-video-id",
      "data-thumbnail-url"
    )
  )
  # remove initial " and ending " and ending ">
  tiOr = apply(tiOr, 2, function(x)
    gsub("(^\")|(\"$)|(\">$)", "", x))
  titles = tiOr[, 1]
  # orders
  orders = tiOr[, 2]
  num = length(titles)
  nameID = formatC(1:num, width = as.integer(log10(num) + 1), flag = "0")
  tmp = sapply(1:num, function(ti) {
    make.names(paste0(nameID[ti], titles[ti], collapse = ""),
               unique = FALSE,
               allow_ = TRUE)
  })
  orderTitle = data.frame(
    Orders = orders,
    VideoTitles = titles,
    fileName = tmp,
    stringsAsFactors = FALSE
  )
  # the line containing ture url
  id = grep(
    "<a href=\"\\/watch\\?v=.*&amp;index",
    urlpage,
    perl = FALSE,
    value = TRUE
  )
  if (length(id) == 0) {
    fileConn <- file("wrongPage.html")
    writeLines(urlpage, fileConn)
    close(fileConn)
    print(paste0("please go to ", getwd(), "/wrongPage.html"))
    stop("loading page failed, please rerun")
  } else {
    id2 = strsplit2(id, "=")
    v = strsplit2(id2[, 3], "\\&")[, 1] # v=
    index = strsplit2(id2[, 4], "\\&")[, 1] # index=
    list0 = param_get(urlSeed, parameter_names = "list") # list=
    orderTitle$URL = paste0('https://www.youtube.com/watch?v=',
                            v,
                            "&list=",
                            list0,
                            "&index=",
                            index) # generate url
    foldID = grep(
      paste0(
        "\\/playlist\\?list=",
        list0,
        "\" class=\" yt-uix-sessionlink      spf-link "
      ),
      urlpage,
      perl = TRUE,
      value = TRUE
    )
    folderName = substr(foldID,
                        regexpr("\" >", foldID) + 3,
                        regexpr("<\\/a>", foldID) - 1)
    folderName = file.path(path, make.names(folderName))
    cat("Table file is saved in: ", folderName, "\n")
    if (!dir.exists(folderName))
      dir.create(folderName, recursive = TRUE)
    # save file name and URLs
    if (saveFileList)
      write.csv(orderTitle, paste0(folderName, "/fileNameOrders.csv"))
    return(list(fileTable = orderTitle, folderName = folderName))
  }
}
